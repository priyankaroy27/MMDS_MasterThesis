{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e1a433-cdec-4f9d-83b5-110de1feccfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AMI-SDM.SpeakerDiarization.only_words' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI-SDM.SpeakerDiarization.mini' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.only_words' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.mini' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.word_and_vocalsounds' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "\u001b[92m\u001b[1m\u001b[4mtrain\u001b[0m\n",
      "   28 files\n",
      "   8h46m annotated\n",
      "   6h11m of speech (71%)\n",
      "   112 speakers\n",
      "\u001b[92m\u001b[1m\u001b[4mdevelopment\u001b[0m\n",
      "   3 files\n",
      "   0h56m annotated\n",
      "   0h40m of speech (72%)\n",
      "   12 speakers\n",
      "\u001b[92m\u001b[1m\u001b[4mtest\u001b[0m\n",
      "   3 files\n",
      "   0h56m annotated\n",
      "   0h39m of speech (70%)\n",
      "   12 speakers\n"
     ]
    }
   ],
   "source": [
    "!PYANNOTE_DATABASE_CONFIG=\"/work/proy/AMI-diarization-setup/pyannote/database.yml\" pyannote-database info AMI-SDM.SpeakerDiarization.mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33938639-831c-4e9d-a6b2-f0fb41670380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AMI-SDM.SpeakerDiarization.only_words' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI-SDM.SpeakerDiarization.mini' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.only_words' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.mini' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n",
      "'AMI.SpeakerDiarization.word_and_vocalsounds' found in /work/proy/AMI-diarization-setup/pyannote/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n"
     ]
    }
   ],
   "source": [
    "from pyannote.database import registry, FileFinder\n",
    "\n",
    "registry.load_database(\"/work/proy/AMI-diarization-setup/pyannote/database.yml\")\n",
    "dataset = registry.get_protocol(\"AMI-SDM.SpeakerDiarization.mini\", {\"audio\": FileFinder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204b5d6b-6b60-4a78-8c68-7b2f6b711677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be63e623-d74e-46de-92b6-9237cf9ea3fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      2\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/NOTSOFAR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"microsoft/NOTSOFAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138116e1-68f8-4b32-b461-fedeaf4f56d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4efb937a9f4c21a953beebba5610f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4327f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x86_64\n"
     ]
    }
   ],
   "source": [
    "# import platform\n",
    "# print(platform.processor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3929b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "NVIDIA RTX 5000 Ada Generation\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ec1cbc-06b2-4e4b-85b2-6af83bae6979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu124\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(torch.__version__)  # Should output 2.5.1+cu124\n",
    "print(torch.version.cuda)  # Should output 12.4\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a41eedb-ede4-4746-b964-1f4c711f2da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9505a121-1871-46c8-aab2-8525846c2e01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol AMI-SDM.SpeakerDiarization.mini does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:47: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pytorch-lightning 2.0.2, yours is 1.6.5. Bad things will probably happen unless you upgrade pytorch-lightning to 2.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/core/model.py:245: UserWarning: Model has been trained for a different task. For fine tuning or transfer learning, it is recommended to train task-dependent layers for a few epochs before training the whole model: ['classifier', 'activation'].\n",
      "  warnings.warn(msg)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name              | Type             | Params | In sizes      | Out sizes                                  \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | sincnet           | SincNet          | 42.6 K | [1, 1, 64000] | [1, 60, 234]                               \n",
      "1 | lstm              | LSTM             | 1.4 M  | [1, 234, 60]  | [[1, 234, 256], [[8, 1, 128], [8, 1, 128]]]\n",
      "2 | linear            | ModuleList       | 49.4 K | ?             | ?                                          \n",
      "3 | classifier        | Linear           | 129    | [1, 234, 128] | [1, 234, 1]                                \n",
      "4 | activation        | Sigmoid          | 0      | [1, 234, 1]   | [1, 234, 1]                                \n",
      "5 | validation_metric | MetricCollection | 0      | ?             | ?                                          \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.890     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3debf605f74476b91476cd5fb8e6815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:106: Your `IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), `__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93582f91c3d14d6f91486f06f555ae1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch_audiomentations/core/transforms_interface.py:225: UserWarning: target_rate is required by Identity. It has been automatically inferred from targets shape to 58. If this is incorrect, you can pass it directly.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Process Process-124:\n",
      "Process Process-138:\n",
      "Process Process-132:\n",
      "Process Process-133:\n",
      "Process Process-128:\n",
      "Process Process-131:\n",
      "Process Process-134:\n",
      "Process Process-137:\n",
      "Process Process-123:\n",
      "Process Process-136:\n",
      "Process Process-130:\n",
      "Process Process-129:\n",
      "Process Process-135:\n",
      "Process Process-126:\n",
      "Process Process-125:\n",
      "Process Process-127:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1060, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# #Create OSD task & fine-tune \"pyannote/segmentation-3.0\" model\n",
    "# from pyannote.audio.tasks import OverlappedSpeechDetection\n",
    "# from pyannote.audio.core.model import Model\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "# osd_task = OverlappedSpeechDetection(\n",
    "#     dataset,      # same AMI mini dataset\n",
    "#     duration=4.0, # 2s chunks\n",
    "#     batch_size=16\n",
    "# )\n",
    "\n",
    "# osd_model = Model.from_pretrained(\"pyannote/segmentation-3.0\", use_auth_token=True)\n",
    "# osd_model.to(device)\n",
    "# osd_model.task = osd_task\n",
    "\n",
    "# osd_trainer = pl.Trainer(\n",
    "#     max_epochs=60,   # quick example (increase for better performance)\n",
    "#     accelerator=\"gpu\",\n",
    "#     devices=1\n",
    "# )\n",
    "# osd_trainer.fit(osd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a4ae11-1b48-4061-b0f0-a9dc17e3db8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pyannote.audio.pipelines import OverlappedSpeechDetection as OSDPipeline\n",
    "# osd_pipeline = OSDPipeline(osd_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeb729a1-362f-4b66-9f39-ed67e436d4a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/pipeline/parameter.py:160: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  return trial.suggest_uniform(name, self.low, self.high)\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A[W 2025-01-23 14:59:55,290] Trial 2 failed with parameters: {'onset': 0.6628785404514064, 'offset': 0.5191433884741008, 'min_duration_on': 0.6684212716047436, 'min_duration_off': 0.9869344263647783} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/pipeline/optimizer.py\", line 227, in objective\n",
      "    output = pipeline(input)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/core/pipeline.py\", line 325, in __call__\n",
      "    return self.apply(file, **kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/pipelines/overlapped_speech_detection.py\", line 233, in apply\n",
      "    overlapped_speech = self._binarize(segmentations)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/utils/signal.py\", line 297, in __call__\n",
      "    if y > self.onset:\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-23 14:59:55,293] Trial 2 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3300655/3297456854.py\", line 5, in <module>\n",
      "    best = optimizer.tune(validation_files, n_iterations=150, show_progress=True)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/pipeline/optimizer.py\", line 327, in tune\n",
      "    self.study_.optimize(objective, n_trials=n_iterations, timeout=None, n_jobs=1)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/study.py\", line 475, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 63, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 160, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 248, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/pipeline/optimizer.py\", line 227, in objective\n",
      "    output = pipeline(input)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/core/pipeline.py\", line 325, in __call__\n",
      "    return self.apply(file, **kwargs)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/pipelines/overlapped_speech_detection.py\", line 233, in apply\n",
      "    overlapped_speech = self._binarize(segmentations)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/utils/signal.py\", line 297, in __call__\n",
      "    if y > self.onset:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 579, in _process_state\n",
      "    rex = cls._process_regex(tdef[0], rflags, state)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 507, in _process_regex\n",
      "    regex = regex.get()\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 495, in get\n",
      "    return regex_opt(self.words, prefix=self.prefix, suffix=self.suffix)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 91, in regex_opt\n",
      "    return prefix + regex_opt_inner(strings, '(') + suffix\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in regex_opt_inner\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 77, in <genexpr>\n",
      "    '|'.join(regex_opt_inner(list(group[1]), '')\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 66, in regex_opt_inner\n",
      "    strings_rev = [s[::-1] for s in strings]\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/regexopt.py\", line 66, in <listcomp>\n",
      "    strings_rev = [s[::-1] for s in strings]\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3310217) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 877, in format_record\n",
      "    _format_traceback_lines(\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 158, in _format_traceback_lines\n",
      "    line = stack_line.render(pygmented=has_colors).rstrip('\\n') + '\\n'\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/stack_data/core.py\", line 391, in render\n",
      "    start_line, lines = self.frame_info._pygmented_scope_lines\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/stack_data/core.py\", line 824, in _pygmented_scope_lines\n",
      "    lines = _pygmented_with_ranges(formatter, code, ranges)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/stack_data/utils.py\", line 164, in _pygmented_with_ranges\n",
      "    lexer = MyLexer(stripnl=False)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 660, in __call__\n",
      "    cls._tokens = cls.process_tokendef('', cls.get_tokendefs())\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 599, in process_tokendef\n",
      "    cls._process_state(tokendefs, processed, state)\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 563, in _process_state\n",
      "    tokens.extend(cls._process_state(unprocessed, processed,\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 563, in _process_state\n",
      "    tokens.extend(cls._process_state(unprocessed, processed,\n",
      "  File \"/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pygments/lexer.py\", line 581, in _process_state\n",
      "    raise ValueError(f\"uncompilable regex {tdef[0]!r} in state {state!r} of {cls!r}: {err}\") from err\n",
      "ValueError: uncompilable regex <pygments.lexer.words object at 0x7fb440378dc0> in state 'builtins' of <class 'stack_data.utils._pygmented_with_ranges.<locals>.MyLexer'>: DataLoader worker (pid 3310217) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    }
   ],
   "source": [
    "# from pyannote.pipeline import Optimizer\n",
    "# validation_files = list(dataset.development())\n",
    "# optimizer = Optimizer(osd_pipeline)\n",
    "\n",
    "# best = optimizer.tune(validation_files, n_iterations=150, show_progress=True)\n",
    "# print(\"Best parameters:\", best)\n",
    "\n",
    "# # Re-instantiate pipeline with best parameters\n",
    "# best_params = optimizer.best_params\n",
    "# osd_pipeline = OSDPipeline(osd_model).instantiate(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac417c-2e54-46c8-b224-25fcdf8526bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from pyannote.core import Annotation, Timeline\n",
    "\n",
    "# def timeline_to_annotation(timeline: Timeline, label=\"OVERLAP\") -> Annotation:\n",
    "#     annotation = Annotation()\n",
    "#     for segment in timeline:\n",
    "#         annotation[segment] = label\n",
    "#     return annotation\n",
    "\n",
    "# from pyannote.metrics.detection import DetectionErrorRate\n",
    "\n",
    "# osd_metric = DetectionErrorRate()\n",
    "\n",
    "# for file in dataset.test():\n",
    "#     # Hypothesis: OverlappedSpeechDetection pipeline returns an *Annotation* already\n",
    "#     overlap_hyp_annot = osd_pipeline(file)\n",
    "#     print(\"Hypothesis labels:\", overlap_hyp_annot.labels())\n",
    "\n",
    "\n",
    "#     # Reference: get_overlap() returns a *Timeline* that you must convert\n",
    "#     overlap_ref_tl = file[\"annotation\"].get_overlap()\n",
    "#     overlap_ref_annot = timeline_to_annotation(overlap_ref_tl, label=\"OVERLAP\")\n",
    "#     print(\"Reference labels:\", overlap_ref_annot.labels())\n",
    "\n",
    "#     # Pass them both as Annotations\n",
    "#     osd_metric(\n",
    "#         reference=overlap_ref_annot,\n",
    "#         hypothesis=overlap_hyp_annot,\n",
    "#         uem=file.get(\"annotated\", None),\n",
    "#         uri=file[\"uri\"]\n",
    "#     )\n",
    "\n",
    "# print(osd_metric.report(display=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c46867-fe70-45c9-b9fc-51b1eb823597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/pipelines/speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  backend = torchaudio.get_audio_backend()\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/pipelines/speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(backend)\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/tasks/segmentation/mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:47: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.0.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/utils/checkpoints.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(path, map_location=device), strict=False\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/processing/features.py:1215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization at 0x7f137ac91fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=True) \n",
    "pretrained_pipeline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9ff39c-67a2-4eb1-aeea-4ba2d88df2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94674944\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45359a0d-cd42-41a9-92de-ed3a22c56a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation_model: pyannote/segmentation@2022.07\n",
      "embedding: speechbrain/spkrec-ecapa-voxceleb\n",
      "klustering: AgglomerativeClustering\n"
     ]
    }
   ],
   "source": [
    "print(f\"segmentation_model: {pretrained_pipeline.segmentation_model}\")\n",
    "print(f\"embedding: {pretrained_pipeline.embedding}\")\n",
    "print(f\"klustering: {pretrained_pipeline.klustering}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d115872-729e-48c5-a40b-7152cd26d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(pretrained_pipeline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160cb5ab-98fb-4337-bc49-6ecd18340d0c",
   "metadata": {},
   "source": [
    "#Initial_Pipeline_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f77efb2c-9127-4092-bd3b-d22d53196ebb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: IS1009a - DER: 0.25\n",
      "  False Alarm: 43.90\n",
      "  Miss: 77.75\n",
      "  Confusion: 52.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ES2004a - DER: 0.29\n",
      "  False Alarm: 47.12\n",
      "  Miss: 170.81\n",
      "  Confusion: 50.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:178: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n",
      "/home/proy/miniconda3/envs/thesis_env3/lib/python3.9/site-packages/pyannote/database/util.py:284: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(file_uem, names=names, dtype=dtype, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: TS3003a - DER: 0.40\n",
      "  False Alarm: 30.02\n",
      "  Miss: 346.24\n",
      "  Confusion: 37.91\n",
      "The pretrained pipeline reaches a Diarization Error Rate (DER) of 32.4% on AMI-SDM.SpeakerDiarization.mini test set.\n"
     ]
    }
   ],
   "source": [
    "# from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "# from pyannote.core import Annotation\n",
    "\n",
    "# # Initialize the Diarization Error Rate metric\n",
    "# metric = DiarizationErrorRate()\n",
    "\n",
    "# # Loop through test files and evaluate performance\n",
    "# for file in dataset.test():\n",
    "    \n",
    "#     #Apply the pretrained pipeline\n",
    "#     file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "\n",
    "#      # Evaluate its performance with detailed metrics\n",
    "#     detailed_der = metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"], detailed=True)\n",
    "    \n",
    "#     # Print detailed results\n",
    "#     print(f\"File: {file['uri']} - DER: {detailed_der['diarization error rate']:.2f}\")\n",
    "#     print(f\"  False Alarm: {detailed_der['false alarm']:.2f}\")\n",
    "#     print(f\"  Miss: {detailed_der['missed detection']:.2f}\")\n",
    "#     print(f\"  Confusion: {detailed_der['confusion']:.2f}\")\n",
    "\n",
    "# # Print overall DER for the test set\n",
    "# print(f\"The pretrained pipeline reaches a Diarization Error Rate (DER) of {100 * abs(metric):.1f}% on {dataset.name} test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa71aa1-66e9-4fe5-9c5d-ade1df8a55e5",
   "metadata": {},
   "source": [
    "#DER+Total_no._segments+Total_latency_for_eachfile+overall_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15cfd604-52a8-4faa-9e20-3df152e8ff7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: IS1009a - DER: 0.25\n",
      "  False Alarm: 43.90\n",
      "  Miss: 77.75\n",
      "  Confusion: 52.05\n",
      "  Processed in 26.11 seconds, producing 123 segments.\n",
      "\n",
      "File: ES2004a - DER: 0.29\n",
      "  False Alarm: 47.12\n",
      "  Miss: 170.81\n",
      "  Confusion: 50.00\n",
      "  Processed in 32.46 seconds, producing 182 segments.\n",
      "\n",
      "File: TS3003a - DER: 0.40\n",
      "  False Alarm: 30.02\n",
      "  Miss: 346.24\n",
      "  Confusion: 37.91\n",
      "  Processed in 42.67 seconds, producing 230 segments.\n",
      "\n",
      "Total processing time for all files: 101.92 seconds.\n",
      "Latency per file: {'IS1009a': 26.11215877532959, 'ES2004a': 32.4609112739563, 'TS3003a': 42.669275522232056}\n",
      "Segment count per file: {'IS1009a': 123, 'ES2004a': 182, 'TS3003a': 230}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "from pyannote.core import Annotation\n",
    "\n",
    "# Initialize the Diarization Error Rate metric\n",
    "metric = DiarizationErrorRate()\n",
    "\n",
    "# Dictionaries to store latency and segment counts per file\n",
    "latency_dict = {}\n",
    "segment_count_dict = {}\n",
    "\n",
    "# Record the overall start time\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for file in dataset.test():\n",
    "    # Start timer for the individual file\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Apply the pretrained pipeline.\n",
    "    diarization_result: Annotation = pretrained_pipeline(file[\"audio\"])\n",
    "    \n",
    "    # If using a GPU, ensure synchronization so timing is accurate.\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # End timer for the individual file\n",
    "    end_time = time.time()\n",
    "    latency = end_time - start_time\n",
    "    latency_dict[file['uri']] = latency\n",
    "    \n",
    "    # Count the number of produced segments\n",
    "    number_of_segments = sum(1 for _ in diarization_result.itertracks())\n",
    "    segment_count_dict[file['uri']] = number_of_segments\n",
    "\n",
    "    # Evaluate the diarization error rate (DER) with detailed metrics.\n",
    "    detailed_der = metric(\n",
    "        file[\"annotation\"],\n",
    "        diarization_result,\n",
    "        uem=file[\"annotated\"],\n",
    "        detailed=True\n",
    "    )\n",
    "    \n",
    "    # Print the results for this file.\n",
    "    print(f\"File: {file['uri']} - DER: {detailed_der['diarization error rate']:.2f}\")\n",
    "    print(f\"  False Alarm: {detailed_der['false alarm']:.2f}\")\n",
    "    print(f\"  Miss: {detailed_der['missed detection']:.2f}\")\n",
    "    print(f\"  Confusion: {detailed_der['confusion']:.2f}\")\n",
    "    print(f\"  Processed in {latency:.2f} seconds, producing {number_of_segments} segments.\\n\")\n",
    "\n",
    "# Record the overall end time\n",
    "overall_end_time = time.time()\n",
    "\n",
    "# Calculate the total latency for the entire test set\n",
    "total_latency = overall_end_time - overall_start_time\n",
    "print(f\"Total processing time for all files: {total_latency:.2f} seconds.\")\n",
    "\n",
    "# Optionally, print the latency and segment count dictionaries\n",
    "print(\"Latency per file:\", latency_dict)\n",
    "print(\"Segment count per file:\", segment_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbd37e-7f2d-4578-b33f-9807b46b27ff",
   "metadata": {},
   "source": [
    "#Segmentwise_latency(Initial_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc12c5-1b96-421e-8209-cb94c4181ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from pyannote.core import Annotation\n",
    "\n",
    "# # Initialize dictionary to store results\n",
    "# segment_latencies = {}\n",
    "\n",
    "# # Loop through test files\n",
    "# for file in dataset.test():\n",
    "#     # Apply pretrained pipeline to get diarization result\n",
    "#     file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "#     diarization_result: Annotation = file[\"pretrained pipeline\"]\n",
    "\n",
    "#     # Store latency information for the current file\n",
    "#     segment_latencies[file[\"uri\"]] = []\n",
    "\n",
    "#     # Iterate over each segment in the diarization result\n",
    "#     for segment in diarization_result.get_timeline():  # Iterate directly over Timeline\n",
    "#         # Get start time for latency measurement\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         # Process the segment using the pretrained pipeline\n",
    "#         # Here we assume you can pass segments directly to the pipeline for isolated processing\n",
    "#         # (Alternatively, crop the audio and pass it if needed)\n",
    "#         _ = pretrained_pipeline({\"audio\": file[\"audio\"], \"segment\": segment})\n",
    "\n",
    "#         # Get end time and calculate latency\n",
    "#         end_time = time.time()\n",
    "#         segment_latency = end_time - start_time\n",
    "\n",
    "#         # Save segment and its latency\n",
    "#         segment_latencies[file[\"uri\"]].append((segment, segment_latency))\n",
    "\n",
    "#     # Print segment-wise latency for the file\n",
    "#     print(f\"File: {file['uri']}\")\n",
    "#     for seg, latency in segment_latencies[file[\"uri\"]]:\n",
    "#         print(f\"  Segment: [{seg.start:.2f} -> {seg.end:.2f}] - Latency: {latency:.2f} seconds\")\n",
    "\n",
    "# # Example: To access latencies later\n",
    "# # print(segment_latencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b28fb8-1786-4132-84ff-c75c3ca061da",
   "metadata": {},
   "source": [
    "#Finetuning_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9efc69d7-0d79-4d83-8756-55d5905a75dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f6ff77f1730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa8a4591-4d04-40fc-82c1-aacce4eeac6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.0.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.4.1+cu124. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:47: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyanNet(\n",
       "  (sincnet): SincNet(\n",
       "    (wav_norm1d): InstanceNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv1d): ModuleList(\n",
       "      (0): Encoder(\n",
       "        (filterbank): ParamSincFB()\n",
       "      )\n",
       "      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n",
       "      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (pool1d): ModuleList(\n",
       "      (0-2): 3 x MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (norm1d): ModuleList(\n",
       "      (0): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (1-2): 2 x InstanceNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(60, 128, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (linear): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.audio import Model\n",
    "model_train = Model.from_pretrained(\"pyannote/segmentation\", use_auth_token=True)\n",
    "model_train.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "804483bb-3ac8-4389-b527-d3d02bfe8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(next(model_train.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eadb14b-7657-4432-8043-a375f4c9bbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 23 20:20:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.142                Driver Version: 550.142        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 5000 Ada Gene...    On  |   00000000:3B:00.0 Off |                  Off |\n",
      "| 30%   36C    P2             46W /  250W |    3446MiB /  32760MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX 5000 Ada Gene...    On  |   00000000:B1:00.0 Off |                  Off |\n",
      "| 30%   29C    P8             19W /  250W |       5MiB /  32760MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2990390      C   ...iconda3/envs/thesis_env5/bin/python       3438MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a17c51-e7ee-40ef-a7ce-61a44ba2326d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol AMI-SDM.SpeakerDiarization.mini does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/tasks/segmentation/speaker_diarization.py:165: UserWarning: `max_num_speakers` has been deprecated in favor of `max_speakers_per_chunk`.\n",
      "  warnings.warn(\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/audio/tasks/segmentation/speaker_diarization.py:169: UserWarning: `loss` has been deprecated and has no effect.\n",
      "  warnings.warn(\"`loss` has been deprecated and has no effect.\")\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.tasks import Segmentation\n",
    "task = Segmentation(\n",
    "    dataset, \n",
    "    duration=model_train.specifications.duration, \n",
    "    max_num_speakers=len(model_train.specifications.classes), \n",
    "    batch_size=32,\n",
    "    num_workers=2, \n",
    "    loss=\"bce\", \n",
    "    vad_loss=\"bce\")\n",
    "model_train.task = task\n",
    "model_train.prepare_data()\n",
    "model_train.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "167d4908-8692-4be7-a4aa-e0f73a9b071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47ce13dd-3e7f-43dd-a8f0-baf3588eb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.device_count())\n",
    "# for i in range(torch.cuda.device_count()):\n",
    "#     print(i, torch.cuda.get_device_name(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b43e0e9-81da-44bf-b013-9f838f42c60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyannote.audio.tasks.segmentation.speaker_diarization.SpeakerDiarization object at 0x7fbfb1c57a00>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698e60ac-cb61-4edd-b173-7d9d74d157f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                   Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 80000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                [1, 60, 293] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 293, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [[1, 293, 256], [[8, 1, 128], [8, 1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    387 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 293, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                 [1, 293, 3] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ Sigmoid          │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 293, 3] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                 [1, 293, 3] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ validation_metric │ MetricCollection │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────────────┴─────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                                  Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │\u001b[37m \u001b[0m\u001b[37m[1, 1, 80000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                               [1, 60, 293]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │\u001b[37m \u001b[0m\u001b[37m [1, 293, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m[[1, 293, 256], [[8, 1, 128], [8, 1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                          ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    387 │\u001b[37m \u001b[0m\u001b[37m[1, 293, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                [1, 293, 3]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ Sigmoid          │      0 │\u001b[37m \u001b[0m\u001b[37m  [1, 293, 3]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                [1, 293, 3]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                          ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────────────┴─────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8280728358749c69947f31da55688eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connec\n",
       "tor.py:240: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connec\n",
       "tor.py:240: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connec\n",
       "tor.py:240: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connec\n",
       "tor.py:240: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the \n",
       "`DataLoader` init to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:106: Your \n",
       "`IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers &gt; 1), \n",
       "`__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:106: Your \n",
       "`IterableDataset` has `__len__` defined. In combination with multi-process data loading (when num_workers > 1), \n",
       "`__len__` could be inaccurate if each worker is not configured independently to avoid having duplicate data.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "# we use Adam optimizer with 1e-4 learning rate\n",
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "model_train.configure_optimizers = MethodType(configure_optimizers, model_train)\n",
    "\n",
    "\n",
    "\n",
    "# we monitor diarization error rate on the validation set\n",
    "# and use to keep the best checkpoint and stop early\n",
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False,\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]\n",
    "\n",
    "# we train for at most 20 epochs (might be shorter in case of early stopping)\n",
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(accelerator=\"gpu\", \n",
    "                  devices = [1],\n",
    "                  callbacks=callbacks, \n",
    "                  max_epochs=30,\n",
    "                  strategy = \"dp\",\n",
    "                  gradient_clip_val=0.5)\n",
    "\n",
    "\n",
    "trainer.fit(model_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19fdaf6-d1b8-4635-8787-2aca9760421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(trainer.strategy.root_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2625b4a-5970-43d0-8efa-e876d1eceafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4996d6ab-4226-499a-b1ed-d12d7be4b67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': {'min_duration_off': 0.5817029604921046,\n",
       "  'threshold': 0.4442333667381752},\n",
       " 'clustering': {'method': 'centroid',\n",
       "  'min_cluster_size': 15,\n",
       "  'threshold': 0.7153814381597874}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_hyperparameters = pretrained_pipeline.parameters(instantiated=True)\n",
    "pretrained_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84bd6653-d1e1-4b03-934e-65062a2452d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:47: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = Model.from_pretrained(checkpoint.best_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd3bdb4-bb11-42de-8b87-621a76d3c5fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyanNet(\n",
       "  (sincnet): SincNet(\n",
       "    (wav_norm1d): InstanceNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (conv1d): ModuleList(\n",
       "      (0): Encoder(\n",
       "        (filterbank): ParamSincFB()\n",
       "      )\n",
       "      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n",
       "      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (pool1d): ModuleList(\n",
       "      (0-2): 3 x MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (norm1d): ModuleList(\n",
       "      (0): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (1-2): 2 x InstanceNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(60, 128, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (linear): ModuleList(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f2c237a-2367-4290-8102-11b42b2c54a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sincnet.wav_norm1d.weight is on device cuda:0\n",
      "sincnet.wav_norm1d.bias is on device cuda:0\n",
      "sincnet.conv1d.0.filterbank.low_hz_ is on device cuda:0\n",
      "sincnet.conv1d.0.filterbank.band_hz_ is on device cuda:0\n",
      "sincnet.conv1d.1.weight is on device cuda:0\n",
      "sincnet.conv1d.1.bias is on device cuda:0\n",
      "sincnet.conv1d.2.weight is on device cuda:0\n",
      "sincnet.conv1d.2.bias is on device cuda:0\n",
      "sincnet.norm1d.0.weight is on device cuda:0\n",
      "sincnet.norm1d.0.bias is on device cuda:0\n",
      "sincnet.norm1d.1.weight is on device cuda:0\n",
      "sincnet.norm1d.1.bias is on device cuda:0\n",
      "sincnet.norm1d.2.weight is on device cuda:0\n",
      "sincnet.norm1d.2.bias is on device cuda:0\n",
      "lstm.weight_ih_l0 is on device cuda:0\n",
      "lstm.weight_hh_l0 is on device cuda:0\n",
      "lstm.bias_ih_l0 is on device cuda:0\n",
      "lstm.bias_hh_l0 is on device cuda:0\n",
      "lstm.weight_ih_l0_reverse is on device cuda:0\n",
      "lstm.weight_hh_l0_reverse is on device cuda:0\n",
      "lstm.bias_ih_l0_reverse is on device cuda:0\n",
      "lstm.bias_hh_l0_reverse is on device cuda:0\n",
      "lstm.weight_ih_l1 is on device cuda:0\n",
      "lstm.weight_hh_l1 is on device cuda:0\n",
      "lstm.bias_ih_l1 is on device cuda:0\n",
      "lstm.bias_hh_l1 is on device cuda:0\n",
      "lstm.weight_ih_l1_reverse is on device cuda:0\n",
      "lstm.weight_hh_l1_reverse is on device cuda:0\n",
      "lstm.bias_ih_l1_reverse is on device cuda:0\n",
      "lstm.bias_hh_l1_reverse is on device cuda:0\n",
      "lstm.weight_ih_l2 is on device cuda:0\n",
      "lstm.weight_hh_l2 is on device cuda:0\n",
      "lstm.bias_ih_l2 is on device cuda:0\n",
      "lstm.bias_hh_l2 is on device cuda:0\n",
      "lstm.weight_ih_l2_reverse is on device cuda:0\n",
      "lstm.weight_hh_l2_reverse is on device cuda:0\n",
      "lstm.bias_ih_l2_reverse is on device cuda:0\n",
      "lstm.bias_hh_l2_reverse is on device cuda:0\n",
      "lstm.weight_ih_l3 is on device cuda:0\n",
      "lstm.weight_hh_l3 is on device cuda:0\n",
      "lstm.bias_ih_l3 is on device cuda:0\n",
      "lstm.bias_hh_l3 is on device cuda:0\n",
      "lstm.weight_ih_l3_reverse is on device cuda:0\n",
      "lstm.weight_hh_l3_reverse is on device cuda:0\n",
      "lstm.bias_ih_l3_reverse is on device cuda:0\n",
      "lstm.bias_hh_l3_reverse is on device cuda:0\n",
      "linear.0.weight is on device cuda:0\n",
      "linear.0.bias is on device cuda:0\n",
      "linear.1.weight is on device cuda:0\n",
      "linear.1.bias is on device cuda:0\n",
      "classifier.weight is on device cuda:0\n",
      "classifier.bias is on device cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in finetuned_model.named_parameters():\n",
    "    print(f\"{name} is on device {param.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a317c46-a0ce-4c0d-8454-bd4d47e02d7e",
   "metadata": {},
   "source": [
    "#Best_Segmentation_Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "955b18ee-b0b3-40d1-9745-87f3603ccbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/pipeline/parameter.py:160: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  return trial.suggest_uniform(name, self.low, self.high)\n",
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:19<00:38, 19.39s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:42<00:21, 21.76s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [01:12<00:00, 25.20s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Segmentation threshold: 0.1559783360635416, Loss: 0.3008887206671236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.97s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.01s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.60s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, Segmentation threshold: 0.762892857030117, Loss: 0.23117892032012824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.91s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.97s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.53s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, Segmentation threshold: 0.762892857030117, Loss: 0.23117892032012824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:13,  7.00s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.08s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.72s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, Segmentation threshold: 0.762892857030117, Loss: 0.23117892032012824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.94s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.02s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:31<00:00, 11.39s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, Segmentation threshold: 0.7579772670265963, Loss: 0.22946632462665406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.87s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.98s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.63s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, Segmentation threshold: 0.24496274802147058, Loss: 0.22893388125261657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:14,  7.08s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.01s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.59s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, Segmentation threshold: 0.4314071253437929, Loss: 0.18791698921698854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.74s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.88s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.47s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, Segmentation threshold: 0.4314071253437929, Loss: 0.18791698921698854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.92s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:18<00:09,  9.47s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.37s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, Segmentation threshold: 0.4314071253437929, Loss: 0.18791698921698854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:14,  7.03s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.09s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.73s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, Segmentation threshold: 0.4314071253437929, Loss: 0.18791698921698854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.93s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.83s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.44s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, Segmentation threshold: 0.4314071253437929, Loss: 0.18791698921698854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.99s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.02s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.61s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, Segmentation threshold: 0.42714558070536796, Loss: 0.1877000812788648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:14,  7.05s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.02s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.79s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, Segmentation threshold: 0.42714558070536796, Loss: 0.1877000812788648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.98s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.02s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.66s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, Segmentation threshold: 0.42714558070536796, Loss: 0.1877000812788648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.93s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.98s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.57s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, Segmentation threshold: 0.42714558070536796, Loss: 0.1877000812788648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.97s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  8.00s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.63s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16, Segmentation threshold: 0.5438589043166423, Loss: 0.1861765591523099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.92s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.89s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.59s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, Segmentation threshold: 0.5438589043166423, Loss: 0.1861765591523099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:14,  7.01s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.07s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.66s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, Segmentation threshold: 0.5159758964316905, Loss: 0.18586911757624858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.95s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  8.00s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.57s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, Segmentation threshold: 0.5159758964316905, Loss: 0.18586911757624858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.87s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.94s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.54s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, Segmentation threshold: 0.5159758964316905, Loss: 0.18586911757624858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:07<00:14,  7.05s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:08,  8.03s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.56s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, Segmentation threshold: 0.5159758964316905, Loss: 0.18586911757624858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:09<00:18,  9.35s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:18<00:08,  8.94s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.07s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, Segmentation threshold: 0.5159758964316905, Loss: 0.18586911757624858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.79s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.89s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.44s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.92s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.91s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.50s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.83s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.93s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.55s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.91s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:18<00:09,  9.39s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.34s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.97s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.98s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.55s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.71s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.75s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.41s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:06<00:13,  6.94s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:15<00:07,  7.97s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:26<00:00,  9.50s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Arent trial:   0%|                                                                        | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[Arent trial:  33%|█████████████████████▎                                          | 1/3 [00:09<00:18,  9.34s/it]\n",
      "\u001b[Arent trial:  67%|██████████████████████████████████████████▋                     | 2/3 [00:18<00:08,  8.94s/it]\n",
      "\u001b[Arent trial: 100%|████████████████████████████████████████████████████████████████| 3/3 [00:29<00:00, 10.09s/it]\n",
      "\u001b[A                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30, Segmentation threshold: 0.5182707799117399, Loss: 0.18583894386687927\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio.pipelines import SpeakerDiarization\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "from pyannote.pipeline import Optimizer\n",
    "\n",
    "    \n",
    "# Instantiate the pipeline\n",
    "pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    clustering=\"OracleClustering\",  \n",
    ")\n",
    "\n",
    "# Set min_duration_off to zero for optimization\n",
    "pipeline.freeze({\"segmentation\": {\"min_duration_off\": 0.0}})\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = Optimizer(pipeline)\n",
    "dev_set = list(dataset.development())  # Full development set\n",
    "\n",
    "# Set iteration limit and best_loss threshold for early stopping\n",
    "max_iterations = 30\n",
    "best_loss = 1.0\n",
    "loss_threshold = 0.1\n",
    "\n",
    "# Tune segmentation threshold\n",
    "iterations = optimizer.tune_iter(dev_set, show_progress=True)\n",
    "for i, iteration in enumerate(iterations):\n",
    "    current_loss = iteration['loss']\n",
    "    print(f\"Iteration {i + 1}, Segmentation threshold: {iteration['params']['segmentation']['threshold']}, Loss: {current_loss}\")\n",
    "\n",
    "    # Update best loss and check for early stopping\n",
    "    if current_loss < best_loss:\n",
    "        best_loss = current_loss\n",
    "    if best_loss < loss_threshold or i >= max_iterations - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57257ef4-4a12-4eb3-9819-93d8b36ccdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/pyannote/pipeline/parameter.py:160: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  return trial.suggest_uniform(name, self.low, self.high)\n"
     ]
    }
   ],
   "source": [
    "best_segmentation_threshold = optimizer.best_params[\"segmentation\"][\"threshold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5989c-ba1c-42fa-a0e9-3ce175578d9a",
   "metadata": {},
   "source": [
    "#Best_clustering_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ba1ffe5-95c7-49f4-892c-a6af6d378b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/utils/checkpoints.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(path, map_location=device), strict=False\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/processing/features.py:1215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.8776427929242292\n",
      "Best clustering threshold so far: 0.6176215414376113\n",
      "Best clustering threshold so far: 0.6176215414376113\n",
      "Best clustering threshold so far: 0.6176215414376113\n",
      "Best clustering threshold so far: 0.6176215414376113\n",
      "Best clustering threshold so far: 0.6176215414376113\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6402755249838252\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n",
      "Best clustering threshold so far: 0.6462499710411432\n"
     ]
    }
   ],
   "source": [
    "pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ").to(device)\n",
    "\n",
    "pipeline.freeze({\n",
    "    \"segmentation\": {\n",
    "        \"threshold\": best_segmentation_threshold,\n",
    "        \"min_duration_off\": 0.0,\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        \"method\": \"centroid\",\n",
    "        \"min_cluster_size\": 15,\n",
    "    },\n",
    "})\n",
    "\n",
    "optimizer = Optimizer(pipeline)\n",
    "iterations = optimizer.tune_iter(dev_set, show_progress=False)\n",
    "best_loss = 1.0\n",
    "for i, iteration in enumerate(iterations):\n",
    "    print(f\"Best clustering threshold so far: {iteration['params']['clustering']['threshold']}\")\n",
    "    if i > 60: break  # 50 iterations should give slightly better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6119bcd2-d21b-4b9d-9fa5-eee00761d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Clustering Threshold: 0.6462499710411432\n"
     ]
    }
   ],
   "source": [
    "best_clustering_threshold = optimizer.best_params[\"clustering\"][\"threshold\"]\n",
    "print(f\"Best Clustering Threshold: {best_clustering_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd984678-4812-43d4-8542-48f786a001df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/utils/checkpoints.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(path, map_location=device), strict=False\n",
      "/home/proy/miniconda3/envs/thesis_env5/lib/python3.9/site-packages/speechbrain/processing/features.py:1215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: IS1009a - DER: 0.22\n",
      "File: ES2004a - DER: 0.27\n",
      "File: TS3003a - DER: 0.25\n",
      "The finetuned pipeline reaches a Diarization Error Rate (DER) of 24.8% on AMI-SDM.SpeakerDiarization.mini test set.\n",
      "        diarization error rate     total      correct            false alarm  \\\n",
      "                             %                                 %               \n",
      "item                                                                           \n",
      "IS1009a              21.650202   695.900   591.635188  85.017271   46.398942   \n",
      "ES2004a              27.307029   923.430   718.362048  77.792799   47.093345   \n",
      "TS3003a              24.748522  1025.964   822.846451  80.202273   50.793379   \n",
      "TOTAL                24.826578  2645.294  2132.843686  80.627850  144.285666   \n",
      "\n",
      "                  missed detection              confusion            \n",
      "                %                           %                     %  \n",
      "item                                                                 \n",
      "IS1009a  6.667473        62.452526   8.974353   41.812287  6.008376  \n",
      "ES2004a  5.099828       137.127440  14.849793   67.940512  7.357408  \n",
      "TS3003a  4.950795       147.184000  14.345922   55.933549  5.451804  \n",
      "TOTAL    5.454428       346.763966  13.108712  165.686348  6.263438  \n"
     ]
    }
   ],
   "source": [
    "# Evaluate final DER on the test set\n",
    "import time\n",
    "finetuned_pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ").to(device)\n",
    "\n",
    "finetuned_pipeline.instantiate({\n",
    "    \"segmentation\": {\n",
    "        \"threshold\": best_segmentation_threshold,\n",
    "        \"min_duration_off\": 0.0,\n",
    "    },\n",
    "    \"clustering\": {\n",
    "        \"method\": \"centroid\",\n",
    "        \"min_cluster_size\": 15,\n",
    "        \"threshold\": best_clustering_threshold,\n",
    "    },\n",
    "})\n",
    "\n",
    "metric = DiarizationErrorRate()\n",
    "\n",
    "# Measure performance on the test set\n",
    "for file in dataset.test():\n",
    "    file[\"finetuned pipeline\"] = finetuned_pipeline(file)\n",
    "    \n",
    "    file_der=metric(file[\"annotation\"], file[\"finetuned pipeline\"], uem=file[\"annotated\"])\n",
    "    \n",
    "    print(f\"File: {file['uri']} - DER: {file_der:.2f}\")\n",
    "\n",
    "print(f\"The finetuned pipeline reaches a Diarization Error Rate (DER) of {100 * abs(metric):.1f}% on {dataset.name} test set.\")\n",
    "final_report_df = metric.report(display=False)\n",
    "print(final_report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77d373-97eb-4924-b01d-1c3f09b3a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "audio_path = Path(file['audio'])  # or construct the full path\n",
    "if not audio_path.is_file():\n",
    "    print(f\"File {audio_path} does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd80ea9-b2f0-4897-88c3-26363d1cb645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063999e5-c6e1-499f-abab-cd5540e887f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "\n",
    "# Dictionary to store overall processing times and segment counts for each file\n",
    "latency_dict = {}\n",
    "segment_count_dict = {}\n",
    "\n",
    "# Record the overall start time\n",
    "overall_start_time = time.time()\n",
    "\n",
    "for file in dataset.test():\n",
    "    audio_path = file[\"audio\"]\n",
    "\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()  # Start profiling\n",
    "\n",
    "    start_time = time.time()\n",
    "    diarization_result: Annotation = finetuned_pipeline(audio_path)\n",
    "    end_time = time.time()\n",
    "\n",
    "    pr.disable()  # Stop profiling\n",
    "\n",
    "    # Get profiling stats\n",
    "    s = io.StringIO()\n",
    "    sortby = 'cumulative'\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "    ps.print_stats(10)  # Print the top 10 slowest functions\n",
    "    print(f\"Profiling stats for file {file['uri']}:\\n{s.getvalue()}\")\n",
    "\n",
    "    latency = end_time - start_time\n",
    "    latency_dict[file['uri']] = latency\n",
    "\n",
    "    # Count how many segments are produced\n",
    "    number_of_segments = sum(1 for _ in diarization_result.itertracks())\n",
    "    segment_count_dict[file['uri']] = number_of_segments\n",
    "\n",
    "    print(f\"File {file['uri']} processed in {latency:.2f} seconds, producing {number_of_segments} segments.\")\n",
    "\n",
    "# Record the overall end time\n",
    "overall_end_time = time.time()\n",
    "\n",
    "# Calculate the overall latency\n",
    "total_latency = overall_end_time - overall_start_time\n",
    "print(f\"Total processing time for all files: {total_latency:.2f} seconds.\")\n",
    "\n",
    "# At the end, print the collected data for individual files\n",
    "print(latency_dict)\n",
    "print(segment_count_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65f17a-6809-4e6a-af80-d08ba045b500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env5",
   "language": "python",
   "name": "thesis_env5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
